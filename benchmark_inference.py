"""
benchmark_inference.py  [E]
============================
æ¨ç†ç¨€ç–åŠ é€Ÿå®éªŒï¼š
  1. åŠ è½½è®­ç»ƒå¥½çš„ 1D DisplacementPINN
  2. æ ‡å‡†æ¨ç† vs é—¨æ§å‰ªææ¨ç†ï¼ˆgate < threshold â†’ è·³è¿‡åœºæ›´æ–°ï¼‰
  3. æµ‹é‡å»¶è¿Ÿï¼ˆlatencyï¼‰ã€ç­‰æ•ˆ FLOPs èŠ‚çœ
  4. è¾“å‡ºå¯¹æ¯”è¡¨ + é€Ÿåº¦æ›²çº¿å›¾

æ— éœ€é‡æ–°è®­ç»ƒã€‚ä»…éœ€ results/displacement_history.pt å­˜åœ¨ã€‚

ç”¨æ³•ï¼š
    python benchmark_inference.py
"""

import os, time
import torch
import torch.nn as nn
import numpy as np
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

from models import DisplacementPINN, DisplacementFieldCell

os.makedirs("results", exist_ok=True)

DEVICE     = "cuda" if torch.cuda.is_available() else "cpu"
HIDDEN_DIM = 64
DEPTH      = 4
THRESHOLDS = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]  # å‰ªæé˜ˆå€¼
BATCH_SIZE = 10000      # æ¨ç†æ‰¹å¤§å°
N_REPEAT   = 200        # å»¶è¿Ÿæµ‹é‡é‡å¤æ¬¡æ•°


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. åŠ è½½æ¨¡å‹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ckpt = torch.load("results/displacement_history.pt",
                  map_location=DEVICE, weights_only=False)
model = DisplacementPINN(hidden_dim=HIDDEN_DIM, depth=DEPTH).to(DEVICE)
model.load_state_dict(ckpt["model"])
model.eval()
print(f"\nâœ… åŠ è½½ DisplacementPINN  (device={DEVICE})")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ç¨€ç–æ¨ç† Forwardï¼ˆå¸¦é˜ˆå€¼å‰ªæï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SparseDisplacementPINN(nn.Module):
    """
    æ¨ç†æ—¶ï¼šgate < threshold çš„ç¥ç»å…ƒç›´é€šï¼ˆè·³è¿‡åœºæ›´æ–°ï¼‰ï¼Œ
    ä¸éœ€è¦é‡æ–°è®­ç»ƒï¼Œåªæ”¹ forward é€»è¾‘ã€‚
    """
    def __init__(self, base_model: DisplacementPINN, threshold: float):
        super().__init__()
        self.input_layer  = base_model.input_layer
        self.cells        = base_model.cells
        self.output_layer = base_model.output_layer
        self.threshold    = threshold

    @torch.no_grad()
    def forward(self, xt: torch.Tensor) -> torch.Tensor:
        u = torch.sin(self.input_layer(xt))
        active_ops = 0
        total_ops  = 0
        for cell in self.cells:
            g = torch.sigmoid(cell.gate_linear(u))
            mask = (g > self.threshold)           # [N, dim] bool
            active_ops += mask.float().sum().item()
            total_ops  += g.numel()
            # åªå¯¹æ¿€æ´»ç¥ç»å…ƒåšåœºæ›´æ–°ï¼Œå…¶ä½™ç›´é€š
            h = torch.sin(cell.field_linear(u))
            u = torch.where(mask, g * h + (1 - g) * u, u)
        self._last_active_ratio = active_ops / (total_ops + 1e-9)
        return self.output_layer(u)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. å»¶è¿Ÿæµ‹é‡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def measure_latency(m, xt: torch.Tensor, n_repeat: int, warmup: int = 20) -> float:
    """è¿”å›å¹³å‡æ¨ç†æ—¶é—´ï¼ˆmsï¼‰"""
    m.eval()
    with torch.no_grad():
        for _ in range(warmup):
            _ = m(xt)
        if DEVICE == "cuda":
            torch.cuda.synchronize()
        t0 = time.perf_counter()
        for _ in range(n_repeat):
            _ = m(xt)
        if DEVICE == "cuda":
            torch.cuda.synchronize()
        t1 = time.perf_counter()
    return (t1 - t0) / n_repeat * 1000   # ms


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ç²¾åº¦è¯„ä¼°ï¼ˆL2 vs è§£æè§£ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def eval_l2(m, n: int = 500) -> float:
    from pde import exact_solution
    xs = torch.linspace(0, 1, n, device=DEVICE).unsqueeze(1)
    ts = torch.full((n, 1), 1.0, device=DEVICE)
    xt = torch.cat([xs, ts], dim=-1)
    with torch.no_grad():
        pred = m(xt)
        Ez_p = pred[:, 0:1]
        Ez_t, _ = exact_solution(xs, ts)
        return (torch.norm(Ez_p - Ez_t) / (torch.norm(Ez_t) + 1e-10)).item()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. åŸºçº¿ï¼ˆthreshold=0ï¼Œæ— å‰ªæï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
xt_bench = torch.rand(BATCH_SIZE, 2, device=DEVICE)

print(f"\nâ±  å»¶è¿Ÿæµ‹é‡ (batch={BATCH_SIZE}, repeat={N_REPEAT})")
print(f"{'â”€'*62}")
print(f"{'Threshold':>10} | {'Latency(ms)':>12} | {'Speedup':>8} | {'Active%':>9} | {'L2 Error':>12}")
print(f"{'â”€'*62}")

baseline_latency = None
results = []

for thr in THRESHOLDS:
    sparse_model = SparseDisplacementPINN(model, threshold=thr).to(DEVICE)
    lat = measure_latency(sparse_model, xt_bench, N_REPEAT)

    if thr == 0.0:
        baseline_latency = lat
        speedup = 1.0
    else:
        speedup = baseline_latency / lat

    # è®¡ç®—å®é™…æ¿€æ´»æ¯”
    with torch.no_grad():
        _ = sparse_model(xt_bench)
        active_ratio = sparse_model._last_active_ratio * 100

    l2 = eval_l2(sparse_model)
    results.append((thr, lat, speedup, active_ratio, l2))

    print(f"  thr={thr:.1f}    | {lat:>11.3f} | {speedup:>7.2f}Ã— | {active_ratio:>7.1f}% | {l2:>12.4e}")

print(f"{'â”€'*62}\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. ç»˜å›¾
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DARK_BG = "#0d1117"; PANEL_BG = "#161b22"; GRID_COLOR = "#21262d"
TEXT_COLOR = "#e6edf3"; MUTED = "#8b949e"
BLUE = "#58a6ff"; GREEN = "#3fb950"; ORANGE = "#d29922"; RED = "#f78166"

thrs      = [r[0] for r in results]
lats      = [r[1] for r in results]
speedups  = [r[2] for r in results]
actives   = [r[3] for r in results]
l2s       = [r[4] for r in results]

fig, axes = plt.subplots(1, 3, figsize=(16, 4.5), facecolor=DARK_BG)

def apply_dark(ax):
    ax.set_facecolor(PANEL_BG)
    ax.tick_params(colors=MUTED, labelsize=9)
    ax.xaxis.label.set_color(MUTED); ax.yaxis.label.set_color(MUTED)
    ax.title.set_color(TEXT_COLOR)
    ax.grid(True, color=GRID_COLOR, lw=0.6, ls="--", alpha=0.7)
    for sp in ax.spines.values(): sp.set_edgecolor(GRID_COLOR)

# (a) æ¨ç†å»¶è¿Ÿ vs é˜ˆå€¼
apply_dark(axes[0])
axes[0].plot(thrs, lats, "o-", color=BLUE, lw=2, ms=7, label="Latency (ms)")
axes[0].set_xlabel("Gate Pruning Threshold")
axes[0].set_ylabel("Latency (ms)")
axes[0].set_title("(a) Inference Latency vs. Threshold")
axes[0].legend(facecolor="#21262d", edgecolor=GRID_COLOR, labelcolor=TEXT_COLOR)

# (b) åŠ é€Ÿæ¯” + æ¿€æ´»ç‡
apply_dark(axes[1])
ax1b = axes[1].twinx()
axes[1].plot(thrs, speedups, "o-", color=GREEN, lw=2, ms=7, label="Speedup")
ax1b.plot(thrs, actives, "s--", color=ORANGE, lw=1.5, ms=6, label="Active %")
ax1b.set_ylabel("Active Neuron %", color=ORANGE)
ax1b.tick_params(axis="y", colors=ORANGE, labelsize=9)
ax1b.set_facecolor("none")
axes[1].set_xlabel("Gate Pruning Threshold")
axes[1].set_ylabel("Speedup Ã—", color=GREEN)
axes[1].tick_params(axis="y", colors=GREEN)
axes[1].set_title("(b) Speedup & Active Neuron Rate")
lines1, labs1 = axes[1].get_legend_handles_labels()
lines2, labs2 = ax1b.get_legend_handles_labels()
axes[1].legend(lines1+lines2, labs1+labs2,
               facecolor="#21262d", edgecolor=GRID_COLOR, labelcolor=TEXT_COLOR, fontsize=9)

# (c) L2 è¯¯å·® vs é˜ˆå€¼ï¼ˆç²¾åº¦ä¿æŒæ›²çº¿ï¼‰
apply_dark(axes[2])
axes[2].semilogy(thrs, l2s, "D-", color=RED, lw=2, ms=7)
axes[2].axhline(l2s[0], color=MUTED, lw=1, ls=":", label=f"No pruning (L2={l2s[0]:.2e})")
axes[2].set_xlabel("Gate Pruning Threshold")
axes[2].set_ylabel("Relative L2 Error")
axes[2].set_title("(c) Accuracy Degradation vs. Threshold")
axes[2].legend(facecolor="#21262d", edgecolor=GRID_COLOR, labelcolor=TEXT_COLOR, fontsize=9)

if speedups[-1] > 1.0:
    best_i = max(range(len(results)),
                 key=lambda i: speedups[i] if l2s[i] < l2s[0] * 2 else -1)
    axes[1].axvline(thrs[best_i], color=GREEN, lw=1, ls="--", alpha=0.5)
    axes[1].text(thrs[best_i]+0.01, speedups[best_i]+0.02,
                 f"Best: {speedups[best_i]:.2f}Ã—\n@ thr={thrs[best_i]:.1f}",
                 color=GREEN, fontsize=8)

fig.suptitle(
    f"Displacement PINN Â· Sparse Inference Benchmark  (device={DEVICE.upper()}, batch={BATCH_SIZE})",
    color=TEXT_COLOR, fontsize=12, fontweight="bold"
)
plt.tight_layout()
path = "results/inference_benchmark.png"
plt.savefig(path, dpi=180, bbox_inches="tight", facecolor=DARK_BG)
plt.close()
print(f"âœ… æ¨ç†åŸºå‡†å›¾ â†’ {path}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. ç»ˆç«¯æ‘˜è¦
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n" + "â•"*62)
print("  ğŸ“Š æ¨ç†ç¨€ç–åŠ é€Ÿå®éªŒç»“è®º")
print("â•"*62)
best = max(results[1:], key=lambda r: r[2])   # æœ€å¤§åŠ é€Ÿæ¯”ï¼ˆæ’é™¤ thr=0ï¼‰
print(f"  æœ€å¤§åŠ é€Ÿæ¯”:  {best[2]:.2f}Ã—  (threshold={best[0]:.1f})")
print(f"  å¯¹åº”æ¿€æ´»ç‡:  {best[3]:.1f}%  ({100-best[3]:.1f}% ç¥ç»å…ƒè¢«å‰ªæ)")
print(f"  å¯¹åº” L2 è¯¯å·®: {best[4]:.4e}  "
      f"{'â†‘ å¯æ¥å—' if best[4] < l2s[0]*2 else 'â†‘ æŸå¤±è¾ƒå¤§'}")
print(f"\n  â†’ æ— éœ€é‡è®­ç»ƒï¼Œgate å‰ªæå³å¯å®ç°æ¨ç†åŠ é€Ÿ")
print(f"  â†’ è¾“å‡º: results/inference_benchmark.png")
print("â•"*62 + "\n")
